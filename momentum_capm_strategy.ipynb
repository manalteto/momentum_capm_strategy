{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "87yPU9TsdGiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Un5tC69AyQBL",
        "outputId": "0f880275-221e-419c-8bd8-f0f754c783c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9f29ece4-b9f0-4f41-b1a8-215c6eb8140c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9f29ece4-b9f0-4f41-b1a8-215c6eb8140c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving msf.csv to msf.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files # Import the 'files' module from the google.colab package. This module is used for file uploading in Google Colab notebooks.\n",
        "uploaded = files.upload() # Call the upload() function from the 'files' module. This opens a file upload prompt, allowing the user to upload files from their local system to the Colab environment. The uploaded files are stored in the 'uploaded' variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]  # Retrieve the filename of the first (and typically only) uploaded file.\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(filename)  # Load the CSV file into a pandas DataFrame. This DataFrame (df) now contains all the data from your CSV file.\n",
        "\n",
        "# Define SIC code ranges for utilities and financial firms\n",
        "utilities_sic_codes = range(4900, 5000)  # Define the range of SIC codes for utilities.\n",
        "financial_sic_codes = range(6000, 6800)  # Define the range of SIC codes for financial firms.\n",
        "\n",
        "# Filter out utilities, financial firms, and stocks priced under $5\n",
        "filtered_df = df[\n",
        "    ~df['HSICCD'].between(4900, 4999) &  # Exclude utilities: stocks with SIC codes 4900-4999.\n",
        "    ~df['HSICCD'].between(6000, 6799) &  # Exclude financial firms: stocks with SIC codes 6000-6799.\n",
        "    (df['PRC'] >= 5)  # Include only stocks with a price of $5 or higher.\n",
        "]\n",
        "\n",
        "# Show the first few lines of the filtered DataFrame\n",
        "print(filtered_df.head())  # Display the first few rows of the filtered DataFrame to verify the filtering process.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDdjIwdxcrZs",
        "outputId": "e117b55e-b2ad-4d43-9bc5-8657c873084e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        CUSIP  PERMNO  PERMCO  ISSUNO  HEXCD  HSICCD      DATE    BIDLO  \\\n",
            "916  00080010   10006   22156       0      1  3743.0  19251231      NaN   \n",
            "917  00080010   10006   22156       0      1  3743.0  19260130  109.125   \n",
            "918  00080010   10006   22156       0      1  3743.0  19260227  101.000   \n",
            "919  00080010   10006   22156       0      1  3743.0  19260331   95.000   \n",
            "920  00080010   10006   22156       0      1  3743.0  19260430   93.000   \n",
            "\n",
            "     ASKHI      PRC  ...        RET      BID     ASK  SHROUT    CFACPR  \\\n",
            "916    NaN  109.000  ...          C  109.375  109.50   600.0  7.412625   \n",
            "917  113.5  110.250  ...   0.032732  109.500  110.25   600.0  7.260000   \n",
            "918  110.0  102.375  ...  -0.071429  102.000  102.50   600.0  7.260000   \n",
            "919  103.0   96.500  ...  -0.042735   96.000   97.00   600.0  7.260000   \n",
            "920   98.0   94.000  ...  -0.025907   93.500   94.50   600.0  7.260000   \n",
            "\n",
            "     CFACSHR   ALTPRC  SPREAD    ALTPRCDT       RETX  \n",
            "916     7.26  109.000     NaN  19251231.0          C  \n",
            "917     7.26  110.250     NaN  19260130.0   0.032732  \n",
            "918     7.26  102.375     NaN  19260227.0  -0.071429  \n",
            "919     7.26   96.500     NaN  19260331.0  -0.057387  \n",
            "920     7.26   94.000     NaN  19260430.0  -0.025907  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert the 'DATE' column in the dataframe to datetime format for easier manipulation\n",
        "df['DATE'] = pd.to_datetime(df['DATE'], format='%Y%m%d')\n",
        "\n",
        "# Convert the 'RET' (returns) column to numeric, coercing any errors (e.g., non-numeric values) to NaN and then forward filling missing returns.\n",
        "# Forward filling is used to handle missing data by carrying the previous valid return forward.\n",
        "df['RET'] = pd.to_numeric(df['RET'], errors='coerce').fillna(method='ffill')\n",
        "\n",
        "# Fill any remaining NaN values in 'RET' with 0, ensuring no disruptions in rolling computations later on\n",
        "df['RET'] = df['RET'].fillna(0)\n",
        "\n",
        "# Filter the dataframe to include only rows from the year 1980 onwards, based on the 'DATE' column\n",
        "df = df[df['DATE'].dt.year >= 1980]\n",
        "\n",
        "# Sort the DataFrame by 'PERMNO' (unique identifier for each security) and 'DATE' to ensure chronological order for each stock, which is critical for rolling calculations\n",
        "df = df.sort_values(['PERMNO', 'DATE'])\n",
        "\n",
        "# Calculate the 12-month rolling average of monthly returns, shifted by one month (using .shift()) to avoid lookahead bias in the analysis\n",
        "df['rolling_avg_ret'] = df.groupby('PERMNO')['RET'].rolling(window=12, min_periods=1).mean().shift().reset_index(level=0, drop=True)\n",
        "\n",
        "# Create a new column 'year_month' to identify the year and month of each record, aiding in monthly groupings and sorting\n",
        "df['year_month'] = df['DATE'].dt.to_period('M')\n",
        "\n",
        "# Rank stocks into deciles based on their 12-month rolling average return at the end of each month, using the newly created 'year_month' for grouping\n",
        "df['decile'] = df.groupby('year_month')['rolling_avg_ret'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop') + 1)\n",
        "\n",
        "# Create a 'next_month' column to identify the subsequent month, which is useful for calculating future returns\n",
        "df['next_month'] = df['year_month'].apply(lambda x: x + 1)\n",
        "\n",
        "# Calculate the equal-weighted returns for each decile and next month combination.\n",
        "# This is done by grouping by 'year_month' and 'decile', then shifting the returns to align with the following month\n",
        "df['ew_return'] = df.groupby(['year_month', 'decile'])['RET'].transform('mean').shift(-1)\n",
        "\n",
        "# Drop columns that are no longer needed ('PERMNO', 'rolling_avg_ret') to simplify the DataFrame\n",
        "# Also, filter out the last month's data since it does not have a corresponding 'next month's return\n",
        "df.drop(columns=['PERMNO', 'rolling_avg_ret'], inplace=True)\n",
        "df = df[df['year_month'] < df['year_month'].max()]\n",
        "\n",
        "# The DataFrame now contains the equal-weighted returns for each decile for each month.\n",
        "# As an example, to view the return for the first decile in January 1980:\n",
        "jan_1980_first_decile_return = df[(df['year_month'] == '1980-01') & (df['decile'] == 1)]['ew_return'].iloc[0]\n",
        "print(f\"Equal-weighted return for the first decile in January 1980: {jan_1980_first_decile_return}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFjLudvHitZa",
        "outputId": "34839652-1051-494c-f84c-b6238e461a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equal-weighted return for the first decile in January 1980: -0.004558855445544554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of your code focuses on preparing and transforming the data to calculate the 12-month rolling average returns and then ranks these into deciles. It ensures the data is correctly formatted and sorted, which is crucial for accurate calculations in momentum strategy analysis."
      ],
      "metadata": {
        "id": "1T1S5_b3MgHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average returns for the first (D1) and tenth (D10) deciles\n",
        "d1_returns = df[df['decile'] == 1].groupby('year_month')['ew_return'].mean()  # Average returns for the first decile (D1)\n",
        "d10_returns = df[df['decile'] == 10].groupby('year_month')['ew_return'].mean()  # Average returns for the tenth decile (D10)\n",
        "\n",
        "# Calculate the returns for the D10-D1 spread (difference between the D10 and D1 decile returns)\n",
        "d10_d1_returns = d10_returns - d1_returns  # This represents the momentum spread return\n",
        "\n",
        "# Prepare the portfolio_returns DataFrame to consolidate the results\n",
        "portfolio_returns = pd.DataFrame({\n",
        "    'Date': d1_returns.index,  # Dates corresponding to the returns\n",
        "    'D1': d1_returns.values,  # Returns for the first decile\n",
        "    'D10': d10_returns.values,  # Returns for the tenth decile\n",
        "    'D10_D1': d10_d1_returns.values  # Returns for the D10-D1 spread\n",
        "})\n",
        "\n",
        "# Convert the 'Date' column to the same format as used in the Fama-French data for consistency\n",
        "# This is important for any subsequent analysis or merging with other datasets\n",
        "portfolio_returns['Date'] = portfolio_returns['Date'].dt.to_timestamp().dt.to_period('M')\n",
        "\n",
        "# The portfolio_returns DataFrame is now ready for CAPM analysis, containing average returns for D1, D10, and the D10-D1 spread, indexed by date"
      ],
      "metadata": {
        "id": "2I5jWNysl11C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code focuses on aggregating the returns of specific deciles and computing the difference between the top and bottom deciles. It then organizes these results into a DataFrame that's ready for further CAPM analysis. The conversion of the 'Date' column to match the format of the Fama-French data ensures compatibility for subsequent analysis steps."
      ],
      "metadata": {
        "id": "RuAS_j2zMotg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Remove previous versions of the Fama-French data file (if any) from the Colab environment.\n",
        "# This ensures that only the most recent version of the file is used in the analysis.\n",
        "# Remove unwanted files from the environment.\n",
        "!rm -f 'fama_french (1).csv' 'fama_french (2).csv' 'fama_french.csv'\n",
        "\n",
        "# Prompt the user to upload a new version of the Fama-French data file.\n",
        "# This is necessary for obtaining the most recent or specific dataset needed for the analysis.\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List the files in the current working directory of the Colab environment.\n",
        "# This command ('ls') is used to confirm that the new file has been successfully uploaded.\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "QlOLfr3akmhx",
        "outputId": "85df4c9b-65a5-4f3b-9b67-1eb3fe0db003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ab9b59cb-20e5-48bf-88ed-9cbed991248c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ab9b59cb-20e5-48bf-88ed-9cbed991248c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fama_french.csv to fama_french.csv\n",
            "fama_french.csv  msf.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Fama/French 3 Factors dataset. The header is specified to be at index 4 (i.e., the 5th row in the file).\n",
        "# If the header is not in the 5th row, adjust the 'skiprows' parameter accordingly.\n",
        "ff3_factors = pd.read_csv('fama_french.csv')\n",
        "\n",
        "# Convert the 'Date' column from a string to a datetime object and then to a period format.\n",
        "# This is important for consistency with other datasets (like your portfolio returns dataset) and for ease of time-based analysis.\n",
        "# The 'format' parameter is set to '%Y%m' to match the date format in the dataset, which typically is YearMonth without a day component.\n",
        "ff3_factors['Date'] = pd.to_datetime(ff3_factors['Date'], format='%Y%m').dt.to_period('M')\n",
        "\n",
        "# Check the columns of the loaded DataFrame to ensure that the data is loaded correctly and the 'Date' column is properly formatted.\n",
        "print(ff3_factors.columns)\n",
        "\n",
        "# Now convert the percentage format to decimals by dividing by 100.\n",
        "# This assumes that the Fama-French factors are in percentage format.\n",
        "# You should verify this with the data documentation or by inspecting the values.\n",
        "ff3_factors[['Mkt-RF', 'SMB', 'HML', 'RF']] = ff3_factors[['Mkt-RF', 'SMB', 'HML', 'RF']] / 100\n",
        "\n",
        "# Print the first few rows to confirm the changes.\n",
        "print(ff3_factors.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EadTsew4jSsl",
        "outputId": "9205fa54-37bb-4599-a586-dfa37c38854e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Mkt-RF', 'SMB', 'HML', 'RF'], dtype='object')\n",
            "      Date  Mkt-RF     SMB     HML      RF\n",
            "0  1926-07  0.0296 -0.0256 -0.0243  0.0022\n",
            "1  1926-08  0.0264 -0.0117  0.0382  0.0025\n",
            "2  1926-09  0.0036 -0.0140  0.0013  0.0023\n",
            "3  1926-10 -0.0324 -0.0009  0.0070  0.0032\n",
            "4  1926-11  0.0253 -0.0010 -0.0051  0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code focuses on importing the Fama-French 3 Factors data and converting the 'Date' column to a period format. This format conversion is crucial for aligning the Fama-French data with your stock returns data for subsequent analysis, such as CAPM regressions."
      ],
      "metadata": {
        "id": "1qwg6QMgNT4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows (head) of the 'portfolio_returns' DataFrame.\n",
        "# This is useful to quickly verify the structure and data of the DataFrame, ensuring it contains the expected columns and format.\n",
        "print(portfolio_returns.head())\n",
        "\n",
        "# Similarly, display the first few rows of the 'ff3_factors' DataFrame.\n",
        "# This helps in confirming that the Fama-French 3 Factors data is loaded correctly and is in the expected format.\n",
        "print(ff3_factors.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KNGX2YXmFTb",
        "outputId": "31a8c370-7396-4bc9-bf55-6066bb43dcab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Date        D1       D10    D10_D1\n",
            "0  1980-01 -0.008045 -0.006728  0.001317\n",
            "1  1980-02 -0.146237 -0.213926 -0.067689\n",
            "2  1980-03  0.046156  0.046206  0.000050\n",
            "3  1980-04  0.058356  0.058438  0.000082\n",
            "4  1980-05  0.025878  0.051933  0.026054\n",
            "      Date  Mkt-RF     SMB     HML      RF\n",
            "0  1926-07  0.0296 -0.0256 -0.0243  0.0022\n",
            "1  1926-08  0.0264 -0.0117  0.0382  0.0025\n",
            "2  1926-09  0.0036 -0.0140  0.0013  0.0023\n",
            "3  1926-10 -0.0324 -0.0009  0.0070  0.0032\n",
            "4  1926-11  0.0253 -0.0010 -0.0051  0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm  # Import the statsmodels library for statistical modeling.\n",
        "\n",
        "# Standardize the column names in the Fama-French factors DataFrame for consistency and clarity.\n",
        "ff3_factors.columns = ['Date', 'Mkt_RF', 'SMB', 'HML', 'RF']\n",
        "\n",
        "# Merge the portfolio returns DataFrame with the Fama-French factors DataFrame on the 'Date' column.\n",
        "# This 'inner' merge ensures that only the rows with matching dates in both DataFrames are included in the final merged DataFrame.\n",
        "df_merged = pd.merge(portfolio_returns, ff3_factors, on='Date', how='inner')\n",
        "\n",
        "# Calculate the excess returns for the D1, D10, and D10-D1 portfolios by subtracting the risk-free rate ('RF') from each portfolio's returns.\n",
        "# Excess returns are the returns of an investment above the risk-free rate and are used in CAPM analysis.\n",
        "df_merged['D1_excess'] = df_merged['D1'] - df_merged['RF']\n",
        "df_merged['D10_excess'] = df_merged['D10'] - df_merged['RF']\n",
        "df_merged['D10_D1_excess'] = df_merged['D10_D1'] - df_merged['RF']\n",
        "\n",
        "# Define the independent variable for the regression (market excess return, 'Mkt_RF') and add a constant term.\n",
        "# The constant term is necessary for the regression to include an intercept.\n",
        "X = sm.add_constant(df_merged['Mkt_RF'])\n",
        "\n",
        "# Initialize an empty DataFrame to store the regression results.\n",
        "# This DataFrame will include the alpha (intercept), beta (slope), and their respective t-statistics for each portfolio.\n",
        "results = pd.DataFrame(columns=['Portfolio', 'Alpha', 'Beta', 't-stat Alpha', 't-stat Beta'])"
      ],
      "metadata": {
        "id": "HlgsKctNKq7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code prepares your data for CAPM regression analysis by merging the portfolio returns with the Fama-French factors, calculating excess returns, and setting up the independent variable and a DataFrame for the results. The statsmodels library is used for the regression analysis, which will be crucial in understanding the risk and return characteristics of the portfolios."
      ],
      "metadata": {
        "id": "TcUtlXMwN7GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows in the merged DataFrame 'df_merged'.\n",
        "# This gives an idea of the size of the dataset after merging the portfolio returns with the Fama-French factors.\n",
        "print(f\"Number of rows in merged DataFrame: {df_merged.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48WkLQFsDjep",
        "outputId": "2698b61e-78f5-4979-8d51-154604c8ad2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in merged DataFrame: 515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a useful check to ensure that the merge operation has resulted in a DataFrame of the expected size."
      ],
      "metadata": {
        "id": "tAyHfib5OGyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty DataFrame for storing the regression results.\n",
        "# This DataFrame will hold the alpha, beta, and their respective t-statistics for each portfolio.\n",
        "results = pd.DataFrame(columns=['Portfolio', 'Alpha', 'Beta', 't-stat Alpha', 't-stat Beta'])\n",
        "\n",
        "# Loop through each portfolio type to perform CAPM regression and gather results.\n",
        "for portfolio in ['D1_excess', 'D10_excess', 'D10_D1_excess']:\n",
        "    # Define the dependent variable (Y) as the excess returns of the current portfolio.\n",
        "    Y = df_merged[portfolio]\n",
        "\n",
        "    # Perform the Ordinary Least Squares (OLS) regression using the market excess return as the independent variable (X).\n",
        "    # The OLS method is a common approach in CAPM analysis to estimate the relationship between portfolio and market returns.\n",
        "    model = sm.OLS(Y, X).fit()\n",
        "\n",
        "    # Extract the alpha and beta (parameters of the regression) and their respective t-statistics.\n",
        "    # Alpha represents the portfolio's return in excess of the return predicted by the CAPM, while beta represents its sensitivity to market movements.\n",
        "    alpha, beta = model.params\n",
        "    t_alpha, t_beta = model.tvalues\n",
        "\n",
        "    # Compile the current portfolio's results into a DataFrame.\n",
        "    # This step includes the portfolio name, alpha, beta, and their t-statistics.\n",
        "    current_results = pd.DataFrame({\n",
        "        'Portfolio': [portfolio],\n",
        "        'Alpha': [alpha],\n",
        "        'Beta': [beta],\n",
        "        't-stat Alpha': [t_alpha],\n",
        "        't-stat Beta': [t_beta]\n",
        "    })\n",
        "\n",
        "    # Append the current results to the main results DataFrame.\n",
        "    # The ignore_index=True parameter ensures that the index is reset appropriately.\n",
        "    results = pd.concat([results, current_results], ignore_index=True)\n",
        "\n",
        "# Display the final results table, showing the alpha, beta, and their t-statistics for each portfolio.\n",
        "print(results)"
      ],
      "metadata": {
        "id": "gSW8pCOXEJlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28a5f4a-462e-4a51-fb3e-79b5116e0b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Portfolio     Alpha      Beta  t-stat Alpha  t-stat Beta\n",
            "0      D1_excess -0.019278  0.333079     -5.554508     4.409117\n",
            "1     D10_excess  0.021748  0.235906      7.492163     3.733731\n",
            "2  D10_D1_excess  0.037741 -0.092855     15.561024    -1.758904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of code is critical for the analysis as it computes the CAPM alpha and beta for each portfolio, providing insights into their performance relative to the market. The loop efficiently handles the regression for each portfolio type, and the results are neatly compiled into a single DataFrame for easy comparison and interpretation."
      ],
      "metadata": {
        "id": "uuZ8ItdxObpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alpha (Intercept):\n",
        "\n",
        "- For D1_excess, the alpha is -0.019278 with a t-statistic of -5.554508. Since the t-statistic is less than -2 (assuming a 95% confidence level), this is statistically significant, indicating that the portfolio underperformed the risk-free rate.\n",
        "\n",
        "- For D10_excess, the alpha is 0.021748 with a t-statistic of 7.492163. This positive and statistically significant alpha suggests that the portfolio outperformed the risk-free rate.\n",
        "\n",
        "- For D10_D1_excess, the alpha is 0.037741 with a t-statistic of 15.561024, which is highly significant and indicates strong outperformance relative to the risk-free rate.\n",
        "\n",
        "Beta (Market Risk):\n",
        "\n",
        "- For D1_excess, the beta is 0.333079 with a t-statistic of 4.409117. This is significantly different from zero, suggesting that the portfolio has a positive and significant exposure to market risk.\n",
        "\n",
        "- For D10_excess, the beta is 0.235906 with a t-statistic of 3.733731. Similar to D1_excess, this is also significant, indicating a positive market risk exposure, but to a lesser extent.\n",
        "\n",
        "- For D10_D1_excess, the beta is -0.092855 with a t-statistic of -1.758904. This t-statistic is close to the threshold of -2 for significance at the 95% confidence level. It suggests that the portfolio might have a negative exposure to market risk, but it's borderline in terms of statistical significance."
      ],
      "metadata": {
        "id": "Dfc9MDgOe8-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the column names of the DataFrame 'df'.\n",
        "# This is useful for quickly checking what data columns are available in the DataFrame.\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_KMCqb6ulWL",
        "outputId": "537d3ba3-4f3b-4653-f858-744dd564ea85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['CUSIP', 'PERMCO', 'ISSUNO', 'HEXCD', 'HSICCD', 'DATE', 'BIDLO',\n",
            "       'ASKHI', 'PRC', 'VOL', 'RET', 'BID', 'ASK', 'SHROUT', 'CFACPR',\n",
            "       'CFACSHR', 'ALTPRC', 'SPREAD', 'ALTPRCDT', 'RETX', 'year_month',\n",
            "       'decile', 'next_month', 'ew_return'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command is especially helpful in data analysis for getting a quick overview of the DataFrame's structure, ensuring that all expected columns are present before proceeding with further analysis or data manipulation."
      ],
      "metadata": {
        "id": "K4yzyzPTO0th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate the 12-month rolling standard deviation of returns for each stock.\n",
        "# This measures the volatility of stock returns over the past year.\n",
        "df['rolling_std_dev'] = df.groupby('CUSIP')['RET'].rolling(window=12, min_periods=1).std().shift().reset_index(level=0, drop=True)\n",
        "\n",
        "# Step 2: Rank the stocks each month based on their rolling standard deviation.\n",
        "# Stocks are ranked in reverse order (lower standard deviation gets a higher rank).\n",
        "# The 'duplicates' parameter set to 'drop' handles cases where multiple stocks have the same standard deviation.\n",
        "df['std_dev_decile'] = df.groupby('year_month')['rolling_std_dev'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
        "\n",
        "# Convert the 'std_dev_decile' to a numerical type and fill NaN values with -1.\n",
        "# NaN values can occur if there is not enough data to rank some stocks.\n",
        "df['std_dev_decile'] = pd.to_numeric(df['std_dev_decile'], errors='coerce').fillna(-1)\n",
        "\n",
        "# Step 3: Create the combined decile ranking (DD) by summing the momentum and volatility deciles.\n",
        "df['DD'] = df['decile'] + df['std_dev_decile']\n",
        "\n",
        "# Step 4: Construct the Portfolio based on the combined ranking (DD).\n",
        "# Select long positions (highest DD values) and short positions (lowest DD values).\n",
        "long_positions = df[df['DD'].isin([20, 19])]\n",
        "short_positions = df[df['DD'].isin([2, 3])]\n",
        "\n",
        "# Calculate the mean returns for long and short positions, shifting by one month to avoid lookahead bias.\n",
        "long_returns = long_positions.groupby(['year_month'])['RET'].mean().shift(-1)\n",
        "short_returns = short_positions.groupby(['year_month'])['RET'].mean().shift(-1)\n",
        "\n",
        "# Calculate the net portfolio returns by subtracting short returns from long returns.\n",
        "portfolio_returns_DD = long_returns - short_returns\n",
        "\n",
        "# Prepare the final DataFrame to display the net returns of the portfolio.\n",
        "final_portfolio_returns_DD = pd.DataFrame({\n",
        "    'Date': portfolio_returns_DD.index,\n",
        "    'Net_Return': portfolio_returns_DD.values\n",
        "})\n",
        "\n",
        "# Display the first few rows of the final portfolio returns for a quick overview.\n",
        "print(final_portfolio_returns_DD.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFoy2qPurRGS",
        "outputId": "8a473ef5-80bd-46dc-d1ff-aed898fea253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Date  Net_Return\n",
            "0  1980-01   -0.249611\n",
            "1  1980-02         NaN\n",
            "2  1980-03   -0.018192\n",
            "3  1980-04   -0.037510\n",
            "4  1980-05   -0.012064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code effectively combines the concepts of momentum (based on past returns) and volatility (measured by standard deviation) to create a more nuanced investment strategy. It then calculates and displays the returns of a portfolio that takes long positions in stocks with the highest combined ranking and short positions in those with the lowest."
      ],
      "metadata": {
        "id": "gbrnGB2xPLeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results here show the net returns of the portfolio for the first few months, starting in 1980. The negative returns in several months suggest that the strategy might not have yielded favorable outcomes initially.\n",
        "\n"
      ],
      "metadata": {
        "id": "asQ29QKAfLPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_capm_regression(portfolio_returns, market_returns):\n",
        "    # Drop any NaN values from the portfolio returns and check if the series is empty.\n",
        "    Y = portfolio_returns.dropna()\n",
        "    if Y.empty:\n",
        "        return [np.nan] * 4  # Return a list of NaNs if there are no data points to analyze.\n",
        "\n",
        "    # Align market returns with the portfolio returns dates.\n",
        "    X = market_returns.loc[Y.index]\n",
        "    # Add a constant to the market returns to include an intercept in the regression model.\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    # Perform the Ordinary Least Squares (OLS) regression and fit the model.\n",
        "    model = sm.OLS(Y, X).fit()\n",
        "    # Return the alpha (constant term), beta (coefficient for market returns), and their respective t-statistics.\n",
        "    return model.params['const'], model.params['Mkt_RF'], model.tvalues['const'], model.tvalues['Mkt_RF']\n",
        "\n",
        "# Align market returns with the dates of the portfolio returns for accurate comparison.\n",
        "market_returns = df_merged.set_index('Date')['Mkt_RF']\n",
        "\n",
        "# Calculate the excess returns for the long, short, and the spread (long-short) portfolios.\n",
        "long_excess_returns = long_returns - df_merged.set_index('Date')['RF']\n",
        "short_excess_returns = short_returns - df_merged.set_index('Date')['RF']\n",
        "spread_excess_returns = (long_returns - short_returns) - df_merged.set_index('Date')['RF']\n",
        "\n",
        "# Perform the CAPM regression for each of the three portfolios (long, short, and spread).\n",
        "long_alpha, long_beta, long_t_alpha, long_t_beta = perform_capm_regression(long_excess_returns, market_returns)\n",
        "short_alpha, short_beta, short_t_alpha, short_t_beta = perform_capm_regression(short_excess_returns, market_returns)\n",
        "spread_alpha, spread_beta, spread_t_alpha, spread_t_beta = perform_capm_regression(spread_excess_returns, market_returns)\n",
        "\n",
        "# Compile the regression results into a DataFrame for reporting.\n",
        "results = pd.DataFrame({\n",
        "    'Portfolio': ['Long', 'Short', 'Spread'],\n",
        "    'Alpha': [long_alpha, short_alpha, spread_alpha],\n",
        "    'Beta': [long_beta, short_beta, spread_beta],\n",
        "    't-stat Alpha': [long_t_alpha, short_t_alpha, spread_t_alpha],\n",
        "    't-stat Beta': [long_t_beta, short_t_beta, spread_t_beta]\n",
        "})\n",
        "\n",
        "# Print the results DataFrame to display the Alpha, Beta, and their respective t-statistics for each portfolio.\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJKLruZixQH_",
        "outputId": "24d302a8-8364-4285-82b5-55dcb4bcae53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Portfolio     Alpha      Beta  t-stat Alpha  t-stat Beta\n",
            "0      Long  0.008655  0.344117      2.208562     4.037678\n",
            "1     Short -0.005663  0.189795     -3.778194     5.817206\n",
            "2    Spread  0.010806  0.160614      3.346756     2.287433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Long Portfolio:\n",
        "\n",
        "Alpha: The alpha is 0.008655 with a t-statistic of 2.208562. Since the t-statistic is greater than 2, the alpha is statistically significant at the 95% confidence level, suggesting that the long portfolio has outperformed the risk-free rate after adjusting for market risk.\n",
        "Beta: The beta is 0.344117 with a t-statistic of 4.037678. This is also statistically significant, indicating a positive and significant exposure to market risk.\n",
        "\n",
        "- Short Portfolio:\n",
        "\n",
        "Alpha: The alpha is -0.005663 with a t-statistic of -3.778194. This negative alpha is statistically significant, meaning the short portfolio has underperformed the risk-free rate, which is expected for a short position.\n",
        "Beta: The beta is 0.189795 with a t-statistic of 5.817206, which is significantly different from zero. The positive beta suggests that the short portfolio has a positive exposure to market risk, which might seem counterintuitive for a short portfolio. This could be due to various factors, such as the types of stocks shorted or market conditions.\n",
        "\n",
        "- Spread Portfolio:\n",
        "\n",
        "Alpha: The alpha is 0.010806 with a t-statistic of 3.346756. This positive and statistically significant alpha indicates that the spread strategy (long-short) has yielded returns above the risk-free rate, signifying successful performance.\n",
        "Beta: The beta is 0.160614 with a t-statistic of 2.287433. The positive beta is marginally statistically significant at the 95% confidence level, suggesting the spread portfolio has some level of market risk exposure, though lower than the long-only portfolio.\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "The long portfolio shows significant positive performance above the risk-free rate.\n",
        "The short portfolio's negative alpha is also significant, indicating underperformance as expected for short positions.\n",
        "The spread portfolio has a significant positive alpha, suggesting effective performance of the strategy, and its beta indicates some market risk exposure but less than a straightforward long position."
      ],
      "metadata": {
        "id": "LYs8DrLqezE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison and Explanation:**\n",
        "\n",
        "\n",
        "**Alpha (Performance relative to the risk-free rate):**\n",
        "\n",
        "- The Long portfolio with momentum (second table) performed better than the Long portfolio without momentum (first table), moving from a significantly negative alpha to a positive one.\n",
        "\n",
        "- The Short portfolio's performance worsened with the inclusion of momentum, changing from a positive to a negative alpha.\n",
        "\n",
        "- The Spread portfolio's alpha increased with momentum, suggesting that the strategy benefitted from the inclusion of the momentum factor.\n",
        "\n",
        "**Beta (Market risk exposure):**\n",
        "\n",
        "- The Long portfolio's beta remained relatively stable with the inclusion of momentum, suggesting consistent market risk exposure.\n",
        "\n",
        "- The Short portfolio's beta decreased slightly with momentum, indicating reduced market risk exposure when momentum is considered.\n",
        "\n",
        "- The Spread portfolio's beta became positive and significant with momentum, in contrast to the negative, borderline significant beta without momentum.\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "The results suggest that incorporating momentum into the strategy has a significant impact on performance (alpha) and alters the market risk exposure (beta) to some extent. Specifically:\n",
        "\n",
        "- The Long momentum portfolio is now outperforming the risk-free rate, whereas the Long portfolio without momentum was underperforming.\n",
        "\n",
        "- The Short portfolio's performance deteriorates with momentum, underlining the potential impact of momentum in driving short positions.\n",
        "\n",
        "- The Spread strategy benefits from the inclusion of momentum, achieving better performance with a statistically significant alpha."
      ],
      "metadata": {
        "id": "bm-1gItKP0Yn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}